{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faec9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('There are different types of data: text files, CSV, JSON objects, HTML and databases.')\n",
    "print('Each data type has a unique extension: .txt, .csv, .json, .html, and so on(depending on th database used)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv\n",
    "print('csv data type')\n",
    "csv_df = pd.read_csv('sample_file.csv') #- reading a datatype by its extension and also including the dataset path from your working directory\n",
    "csv_df.to_csv('sample_file.csv', index=False) #- The format of the dataset should be a csv format and the first column in the dataset should be the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel\n",
    "#sometimes dependent on the xlrd library which can be installed by running pip\n",
    "print('excel data type')\n",
    "install xlrd in the terminal\n",
    "excel_df = pd.read_excel('sample_file.xlsx')\n",
    "excel_df.to_excel('sample_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06aaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#html\n",
    "#read table from a webpage and save as a dataframe\n",
    "print('html data type')\n",
    "html_df = pd.read_html('http://www.webpage.com/sampledata.html')\n",
    "html_df.to_html('sample_file.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database\n",
    "print('Pandas can connect to databases, get data with queries and save in a dataframe.')'\n",
    "url='https://github.com/WalePhenomenon/climate_change/blob/master/fuel_ferc1.csv?raw=true'\n",
    "fuel_data = pd.read_csv(url, error_bad_lines=False)\n",
    "fuel_data.describe(include='all')\n",
    "#check for missing values\n",
    "fuel_data.isnull().sum() #-Finding the sum of all missing values\n",
    "#use groupby to count the sum of each unique value in the fuel unit column\n",
    "fuel_data.groupby('fuel_unit')['fuel_unit'].count()\n",
    "fuel_data[['fuel_unit']] = fuel_data[['fuel_unit']].fillna(value='mcf') #- Filling empty fields in the fuel_data df with mcf\n",
    "#check if missing values have been filled\n",
    "fuel_data.isnull().sum()\n",
    "fuel_data.groupby('report_year')['report_year'].count()\n",
    "#group by the fuel type code year and print the first entries in all the groups\n",
    "formed\n",
    "fuel_data.groupby('fuel_type_code_pudl').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b208d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Merging in pandas')\n",
    "fuel_df1 = fuel_data.iloc[0:19000].reset_index(drop=True)\n",
    "fuel_df2 = fuel_data.iloc[19000:].reset_index(drop=True)\n",
    "#check that the length of both dataframes sum to the expected length\n",
    "assert len(fuel_data) == (len(fuel_df1) + len(fuel_df2))\n",
    "#an inner merge will lose rows that do not match in both dataframes\n",
    "pd.merge(fuel_df1, fuel_df2, how=\"inner\")\n",
    "#outer merge returns all rows in both dataframes\n",
    "pd.merge(fuel_df1, fuel_df2, how=\"outer\")\n",
    "#removes rows from the right dataframe that do not have a match with the left\n",
    "#and keeps all rows from the left\n",
    "pd.merge(fuel_df1, fuel_df2, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Concatenation in pandas')\n",
    "print('This simply means to join and it is performed with the concat() function')\n",
    "pd.concat([fuel_data, data_to_concat]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duplicates are a common occurrence in datasets which alter the results of data analysis.')\n",
    "#check for duplicate rows\n",
    "fuel_data.duplicated().any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
